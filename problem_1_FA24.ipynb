{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Problem 1**\n",
        "\n"
      ],
      "metadata": {
        "id": "pENuF55eXoFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load data\n",
        "X_train = np.loadtxt('X_train.txt')\n",
        "X_test = np.loadtxt('X_test.txt')\n",
        "y_train = np.loadtxt('y_train.txt')\n",
        "y_test = np.loadtxt('y_test.txt')\n"
      ],
      "metadata": {
        "id": "LeB6m9b8UYPH"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transpose the data\n",
        "X_test_transposed = X_test.T\n",
        "\n",
        "# Save the transposed data back to a file\n",
        "np.savetxt('X_test_transposed.txt', X_test_transposed, fmt='%.6f')\n",
        "\n",
        "print(\"File transposed successfully and saved as 'X_test_transposed.txt'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsJ3oNOYUkmO",
        "outputId": "328e0558-3f71-4dfa-fbbd-4f666cd01929"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File transposed successfully and saved as 'X_test_transposed.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tried with only one class"
      ],
      "metadata": {
        "id": "xvUF6hg-Y1ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = SVC(kernel='rbf', gamma='scale', C=1)\n",
        "clf.fit(X_train, y_train[:, 0])  # Train on the first class\n",
        "preds = clf.predict(X_test_transposed)\n",
        "accuracy = np.mean(preds == y_test[:, 0]) * 100\n",
        "print(f\"Accuracy for Class 0 with RBF kernel: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f84iL1sRd0EF",
        "outputId": "3e2f3d42-124b-4ebd-8569-45fc936e963e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Class 0 with RBF kernel: 91.07%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Load data\n",
        "X_train = np.loadtxt('X_train.txt')\n",
        "X_test = np.loadtxt('X_test.txt')\n",
        "y_train = np.loadtxt('y_train.txt')\n",
        "y_test = np.loadtxt('y_test.txt')\n",
        "\n",
        "# Normalize the dataset\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test_transposed)\n",
        "\n",
        "# Grid Search for Hyperparameter Tuning\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': [0.001, 0.01, 0.1, 1, 'scale']\n",
        "}\n",
        "\n",
        "# Train SVM with optimized hyperparameters for each class\n",
        "rbf_classifiers = []\n",
        "for i in range(y_train.shape[1]):\n",
        "    grid = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid, cv=3, scoring='accuracy')\n",
        "    grid.fit(X_train, y_train[:, i])  # Optimize for each class\n",
        "    best_params = grid.best_params_\n",
        "    print(f\"Class {i}: Best parameters: {best_params}\")\n",
        "\n",
        "    # Train with the best parameters\n",
        "    clf = SVC(kernel='rbf', C=best_params['C'], gamma=best_params['gamma'], class_weight='balanced')\n",
        "    clf.fit(X_train, y_train[:, i])\n",
        "    rbf_classifiers.append(clf)\n",
        "\n",
        "# Predict on the test set\n",
        "rbf_predictions = np.zeros_like(y_test)\n",
        "for i, clf in enumerate(rbf_classifiers):\n",
        "    rbf_predictions[:, i] = clf.predict(X_test)\n",
        "\n",
        "# Compute accuracy for multi-label classification\n",
        "accuracies = []\n",
        "for i in range(len(y_test)):\n",
        "    T = y_test[i]\n",
        "    P = rbf_predictions[i]\n",
        "    numerator = np.sum(np.logical_and(T, P))\n",
        "    denominator = np.sum(np.logical_or(T, P))\n",
        "    if denominator > 0:\n",
        "        accuracies.append(numerator / denominator)\n",
        "\n",
        "rbf_accuracy = np.mean(accuracies) * 100\n",
        "print(f\"Accuracy with Gaussian (RBF) kernel: {rbf_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibmriDgYc7pc",
        "outputId": "0f1b0a58-ddd1-409b-d0be-4a5c64b566c2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0: Best parameters: {'C': 10, 'gamma': 'scale'}\n",
            "Class 1: Best parameters: {'C': 10, 'gamma': 0.001}\n",
            "Class 2: Best parameters: {'C': 10, 'gamma': 'scale'}\n",
            "Class 3: Best parameters: {'C': 1, 'gamma': 'scale'}\n",
            "Class 4: Best parameters: {'C': 10, 'gamma': 'scale'}\n",
            "Class 5: Best parameters: {'C': 10, 'gamma': 0.01}\n",
            "Accuracy with Gaussian (RBF) kernel: 67.66%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Load data\n",
        "X_train = np.loadtxt('X_train.txt')\n",
        "X_test = np.loadtxt('X_test.txt')\n",
        "y_train = np.loadtxt('y_train.txt')\n",
        "y_test = np.loadtxt('y_test.txt')\n",
        "\n",
        "# Normalize the dataset\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test_transposed)\n",
        "\n",
        "# Hyperparameter Grid for Polynomial Kernel\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100]  # Regularization parameter\n",
        "}\n",
        "\n",
        "# Train SVM with optimized hyperparameters for each class\n",
        "poly_classifiers = []\n",
        "for i in range(y_train.shape[1]):\n",
        "    grid = GridSearchCV(SVC(kernel='poly', degree=2, class_weight='balanced'), param_grid, cv=3, scoring='accuracy')\n",
        "    grid.fit(X_train, y_train[:, i])  # Optimize for each class\n",
        "    best_params = grid.best_params_\n",
        "    print(f\"Class {i}: Best parameters: {best_params}\")\n",
        "\n",
        "    # Train with the best parameters\n",
        "    clf = SVC(kernel='poly', degree=2, C=best_params['C'], class_weight='balanced')\n",
        "    clf.fit(X_train, y_train[:, i])\n",
        "    poly_classifiers.append(clf)\n",
        "\n",
        "# Predict on the test set\n",
        "poly_predictions = np.zeros_like(y_test)\n",
        "for i, clf in enumerate(poly_classifiers):\n",
        "    poly_predictions[:, i] = clf.predict(X_test)\n",
        "\n",
        "# Compute accuracy for multi-label classification\n",
        "accuracies = []\n",
        "for i in range(len(y_test)):\n",
        "    T = y_test[i]\n",
        "    P = poly_predictions[i]\n",
        "    numerator = np.sum(np.logical_and(T, P))\n",
        "    denominator = np.sum(np.logical_or(T, P))\n",
        "    if denominator > 0:\n",
        "        accuracies.append(numerator / denominator)\n",
        "\n",
        "poly_accuracy = np.mean(accuracies) * 100\n",
        "print(f\"Accuracy with Polynomial kernel: {poly_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqdzQt52havs",
        "outputId": "32927988-bd20-4066-ba4a-f305c9beb837"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0: Best parameters: {'C': 1}\n",
            "Class 1: Best parameters: {'C': 1}\n",
            "Class 2: Best parameters: {'C': 1}\n",
            "Class 3: Best parameters: {'C': 1}\n",
            "Class 4: Best parameters: {'C': 10}\n",
            "Class 5: Best parameters: {'C': 10}\n",
            "Accuracy with Polynomial kernel: 61.26%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JhmbP7R1mjhw"
      },
      "execution_count": 42,
      "outputs": []
    }
  ]
}